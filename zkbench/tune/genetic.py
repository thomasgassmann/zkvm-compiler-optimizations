import asyncio
import dataclasses
import json
import logging
from opentuner import ConfigurationManipulator
from opentuner import ScheduleParameter, EnumParameter
from opentuner import MeasurementInterface
from opentuner import Result
from opentuner.tuningrunmain import the_logging_config
import opentuner

from zkbench.tune.runner import TuneRunner
from zkbench.tune.common import (
    LTO_OPTIONS,
    OPT_LEVEL_OPTIONS,
    BIN_OUT_GENETIC,
    ProfileConfig,
    TuneConfig,
    build_pass_list,
)


def add_common_params(manipulator: ConfigurationManipulator, config: TuneConfig):
    manipulator.add_parameter(
        EnumParameter("lto", LTO_OPTIONS if config.tune_lto else ["off"])
    )
    manipulator.add_parameter(
        EnumParameter(
            "single_codegen_unit",
            [True, False] if config.tune_codegen_units else [False],
        )
    )
    manipulator.add_parameter(
        EnumParameter(
            "opt_level",
            OPT_LEVEL_OPTIONS if config.tune_opt_level else ["0"],
        )
    )
    manipulator.add_parameter(
        EnumParameter(
            "prepopulate_passes",
            [True, False] if config.tune_prepopulate_passes else [False],
        )
    )


class Mode:
    def get_manipulator(self, config: TuneConfig):
        raise NotImplementedError("This method should be overridden by subclasses.")

    def get_profile_config(self, desired_result) -> ProfileConfig:
        raise NotImplementedError("This method should be overridden by subclasses.")


class DepthMode(Mode):
    def __init__(self, depth: int):
        self.depth = depth

    def get_profile_config(self, desired_result):
        cfg = desired_result.configuration.data
        used_passes = []
        for i in range(self.depth):
            current_pass = cfg[f"depth-{i}"]
            used_passes.append(current_pass)
        return ProfileConfig(
            name="genetic",
            lto=cfg["lto"],
            single_codegen_unit=cfg["single_codegen_unit"],
            opt_level=cfg["opt_level"],
            prepopulate_passes=cfg["prepopulate_passes"],
            passes=[build_pass_list(used_passes)],
        )

    def get_manipulator(self, config: TuneConfig):
        manipulator = ConfigurationManipulator()
        all_passes = config.module_passes + config.function_passes + config.loop_passes
        for i in range(self.depth):
            manipulator.add_parameter(EnumParameter(f"depth-{i}", all_passes))
        add_common_params(manipulator, config)
        return manipulator


class DefaultMode(Mode):

    def get_profile_config(self, desired_result):
        # we can prebild binaries using compile, run_precompiled and compile_and_run
        # however this might cause issues if we build the same program in parallel
        cfg = desired_result.configuration.data
        used_passes = []
        for current_pass in cfg["passes"]:
            if cfg[current_pass] == "on":
                used_passes.append(current_pass)

        # pass is only applied once, we can apply pass multiple times
        pass_list = [build_pass_list(used_passes)]
        return ProfileConfig(
            name="genetic",
            lto=cfg["lto"],
            single_codegen_unit=cfg["single_codegen_unit"],
            opt_level=cfg["opt_level"],
            prepopulate_passes=cfg["prepopulate_passes"],
            passes=pass_list,
        )

    def get_manipulator(self, config: TuneConfig):
        manipulator = ConfigurationManipulator()
        all_passes = config.module_passes + config.function_passes + config.loop_passes
        manipulator.add_parameter(ScheduleParameter("passes", all_passes, {}))
        for current in all_passes:
            manipulator.add_parameter(EnumParameter(current, ["on", "off"]))
        add_common_params(manipulator, config)
        return manipulator


def create_tuner(
    programs: list[str],
    zkvms: list[str],
    metric: str,
    out_stats: str,
    config: TuneConfig,
    mode: Mode,
):
    runner = TuneRunner(out=BIN_OUT_GENETIC, metric=metric)

    class PassTuner(MeasurementInterface):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self._best = float("inf")
            self._best_config = None
            self._values = []
            self._profile_configs = []
            self._metrics = []

        def manipulator(self):
            return mode.get_manipulator(config)

        def run(self, desired_result, input, limit):
            profile_config = mode.get_profile_config(desired_result)

            # first build all the binaries
            try:
                asyncio.get_event_loop().run_until_complete(
                    runner.run_build(
                        programs,
                        zkvms,
                        profile_config,
                    )
                )
            except Exception as e:
                logging.error(f"Error during build for profile {profile_config}: {e}")
                return Result(time=float("inf"), state="ERROR")

            # then calculate metrics
            eval_result = runner.eval_all(programs, zkvms, profile_config)
            if eval_result.has_error:
                return Result(time=float("inf"), state="ERROR")

            values = eval_result.values
            self._metrics.append([dataclasses.asdict(value) for value in values])
            metric_sum = sum([v.metric for v in values])
            self._values.append(metric_sum)
            self._profile_configs.append(dataclasses.asdict(profile_config))

            logging.info(f"Configuration {profile_config} has metric {metric_sum}")
            if metric_sum < self._best or self._best_config is None:
                logging.info(
                    f"Found better configuration: {profile_config} with metric {metric_sum}"
                )
                self._best = metric_sum
                self._best_config = profile_config
            else:
                logging.info(
                    f"Configuration {self._best_config} remains best with metric {self._best}"
                )

            with open(out_stats, "w") as f:
                json.dump(
                    {
                        "profile_configs": self._profile_configs,
                        "values": self._values,
                        "metrics": self._metrics,
                        "best_metric": self._best,
                        "best_profile": dataclasses.asdict(self._best_config),
                        "metric": metric,
                        "programs": programs,
                        "zkvms": zkvms,
                        "config": dataclasses.asdict(config),
                    },
                    f,
                )

            return Result(time=metric_sum, state="OK")

    return PassTuner


def run_tune_genetic(
    programs: list[str],
    zkvms: list[str],
    metric: str,
    config: TuneConfig,
    mode: str,
    out_stats: str,
    depth: int | None,
):
    arg_parser = opentuner.default_argparser()

    the_logging_config["handlers"]["console"]["level"] = logging.getLevelName(
        logging.getLogger().level
    )
    the_logging_config["loggers"][""]["level"] = logging.getLevelName(
        logging.getLogger().level
    )

    if mode == "default":
        mode = DefaultMode()
    elif mode == "depth":
        mode = DepthMode(depth)

    create_tuner(programs, zkvms, metric, out_stats, config, mode).main(
        arg_parser.parse_args([])
    )
